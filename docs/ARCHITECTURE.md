# SubsTranslator - System Architecture

## Executive Summary

SubsTranslator is an AI-powered video subtitle generation and translation platform that transforms video content into multilingual, accessible media. The system accepts YouTube URLs or uploaded video files, transcribes audio using OpenAI's Whisper models, translates subtitles into target languages, and produces both standalone SRT files and videos with embedded subtitles. Built for enterprise scale with React/TypeScript frontend, Flask API backend, and Celery worker architecture, it delivers production-grade performance with sophisticated Hebrew/RTL text support and intelligent resource management.

**Core User Flow**: Upload/YouTube URL â†’ Video Download â†’ Audio Extraction â†’ Whisper Transcription â†’ Translation â†’ Subtitle Generation â†’ Video Muxing â†’ Download Artifacts

## System Context Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   End Users     â”‚    â”‚   External      â”‚    â”‚   ML Services   â”‚
â”‚                 â”‚    â”‚   Services      â”‚    â”‚                 â”‚
â”‚ â€¢ Browser UI    â”‚    â”‚ â€¢ YouTube API   â”‚    â”‚ â€¢ Whisper Modelsâ”‚
â”‚ â€¢ Mobile Web    â”‚    â”‚ â€¢ Google Trans â”‚    â”‚ â€¢ OpenAI API    â”‚
â”‚ â€¢ API Clients   â”‚    â”‚ â€¢ CDN Content   â”‚    â”‚ â€¢ Translation   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                      â”‚                      â”‚
          â”‚ HTTPS                â”‚ HTTPS                â”‚ HTTPS
          â–¼                      â–¼                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend      â”‚    â”‚   Backend       â”‚    â”‚   Workers       â”‚
â”‚   (React/TS)    â”‚â—„â”€â”€â–ºâ”‚   (Flask)       â”‚â—„â”€â”€â–ºâ”‚   (Celery)      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ Nginx:80      â”‚    â”‚ â€¢ API:8081      â”‚    â”‚ â€¢ Processing Q  â”‚
â”‚ â€¢ Static Assets â”‚    â”‚ â€¢ Health/Metricsâ”‚    â”‚ â€¢ Cleanup Q     â”‚
â”‚ â€¢ Routing/i18n  â”‚    â”‚ â€¢ File Upload   â”‚    â”‚ â€¢ Beat Schedule â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚                      â”‚
                                 â”‚ TCP                  â”‚ TCP
                                 â–¼                      â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚     Redis       â”‚    â”‚  File Storage   â”‚
                       â”‚   (Message      â”‚    â”‚                 â”‚
                       â”‚    Broker)      â”‚    â”‚ â€¢ uploads/      â”‚
                       â”‚ â€¢ Task Queue    â”‚    â”‚ â€¢ downloads/    â”‚
                       â”‚ â€¢ Results Cache â”‚    â”‚ â€¢ models/       â”‚
                       â”‚ â€¢ Port 6379     â”‚    â”‚ â€¢ assets/       â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                                 â–¼
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚  External Tools â”‚
                       â”‚                 â”‚
                       â”‚ â€¢ yt-dlp        â”‚
                       â”‚ â€¢ FFmpeg        â”‚
                       â”‚ â€¢ faster-whisperâ”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Component Architecture

### Frontend Layer (React/TypeScript)

**Core Structure** (`frontend/src/`):
```typescript
App.tsx                    // Main application component
â”œâ”€â”€ hooks/useApi.ts        // Centralized backend communication
â”œâ”€â”€ contexts/AuthContext   // Authentication state management
â”œâ”€â”€ i18n/I18nProvider     // Internationalization wrapper
â”œâ”€â”€ components/           // Reusable UI components
â”‚   â”œâ”€â”€ UploadForm       // File upload interface
â”‚   â”œâ”€â”€ YoutubeForm      // URL input interface  
â”‚   â”œâ”€â”€ ProgressDisplay  // Real-time processing status
â”‚   â””â”€â”€ ResultsDisplay   // Download links and metadata
â””â”€â”€ routing/LanguageRouter // URL-based language routing
```

**Key Patterns**:
- **Hook-based Architecture**: `useApi.ts` centralizes all backend communication with polling-based progress updates
- **Context Providers**: AuthContext + I18nProvider for cross-component state
- **Error Boundaries**: Structured error handling with i18n error messages
- **RTL Support**: Full Hebrew/Arabic layout with CSS logical properties

### Backend Layer (Flask API)

**Module Structure** (`backend/`):
```python
app.py                     // Flask application + API endpoints
â”œâ”€â”€ config.py             // Environment-based configuration
â”œâ”€â”€ core/exceptions.py    // Structured error hierarchy
â”œâ”€â”€ services/            // Business logic layer
â”‚   â””â”€â”€ subtitle_service // SRT processing and validation
â”œâ”€â”€ i18n/translations    // Backend i18n support
â”œâ”€â”€ state_manager.py     // Thread-safe task state tracking
â””â”€â”€ logging_config.py    // Structured logging with context
```

**API Design Principles**:
- **RESTful Endpoints**: `/youtube`, `/upload`, `/status/{id}`, `/download/{token}`
- **Structured Responses**: Consistent error/success formats with i18n messages
- **Input Validation**: File type/size limits, URL validation, parameter sanitization
- **Error Handling**: Custom exception hierarchy with user-facing translations

### Workers Layer (Celery)

**Task Architecture** (`backend/tasks.py`, `celery_config.py`):
```python
# Task Graph Structure
download_and_process_youtube_task()
â”œâ”€â”€ 1. Video Download (yt-dlp)
â”œâ”€â”€ 2. Audio Extraction (FFmpeg)  
â”œâ”€â”€ 3. Transcription (Whisper)
â”œâ”€â”€ 4. Translation (Google/OpenAI)
â”œâ”€â”€ 5. Subtitle Generation (SRT)
â””â”€â”€ 6. Video Muxing (FFmpeg)

# Queue Architecture
processing_queue          // Main processing tasks
cleanup_queue            // File lifecycle management
default_queue            // System tasks
```

**Design Features**:
- **Idempotent Tasks**: All operations support retries without side effects
- **Progress Tracking**: 6-step FSM with weighted progress calculation
- **Resource Management**: `max-tasks-per-child=1` prevents memory leaks
- **Timeout Protection**: 30min soft limit, 35min hard limit

### Shared Configuration

**Environment Strategy** (`config.py`, `shared_config.py`):
```python
# Configuration Hierarchy
DevelopmentConfig   // Local development settings
ProductionConfig    // Production hardening
TestingConfig      // CI/testing overrides

# Shared Language Data
SUPPORTED_LANGUAGES    // UI languages (he, en, es, ar)
TRANSCRIPTION_LANGUAGES // Extended set for ML processing
```

**Security Model**:
- âœ… Environment variables for all secrets
- âœ… No hardcoded credentials in codebase
- âœ… Secure file handling with path traversal protection

## Data Flow & Processing Pipeline

### YouTube URL Processing Sequence

```
User Input (YouTube URL) â†’ Frontend Validation â†’ Backend API Call
                                                       â†“
Task Creation (Celery) â†’ Redis Queue â†’ Worker Pickup
                                          â†“
Step 1: yt-dlp Download â†’ Temp Storage (/app/uploads)
                             â†“
Step 2: FFmpeg Audio Extract â†’ WAV file
                                  â†“  
Step 3: Whisper Transcription â†’ Original SRT
                                    â†“
Step 4: Google/OpenAI Translation â†’ Translated SRT  
                                       â†“
Step 5: FFmpeg Subtitle Burn-in â†’ Final MP4
                                    â†“
Step 6: File Organization â†’ Downloads folder â†’ Token-based Access
```

### Local Upload Processing Sequence

```
File Upload (multipart/form-data) â†’ Flask Request Handler â†’ Validation
                                                              â†“
Secure Storage (/app/uploads) â†’ Task Queue â†’ Worker Processing
                                               â†“
[Steps 2-6 identical to YouTube flow]
```

### State Management & Progress Tracking

**Finite State Machine** (`state_manager.py:16-50`):
```
PENDING â†’ PROGRESS â†’ SUCCESS
    â†“        â†“          â†‘
    â†“     ERROR â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“        â†“
    â””â”€â”€â”€â”€ FAILURE
```

**Progress Calculation**:
- Each step has configurable weight (download=20%, transcribe=40%, etc.)
- Real-time updates via Redis polling
- Granular sub-step progress within operations

### File Lifecycle Management

**Retention Policy**:
- **Uploads**: Deleted after successful processing or 24h timeout
- **Downloads**: Retained 24h with periodic cleanup (Celery Beat)
- **Models**: Persistent cache with intelligent eviction
- **Logs**: Structured JSON with configurable retention

## Technology Choices & Trade-offs

### Core Stack Rationale

| Technology | Choice | Pros | Cons | Alternative Considered |
|------------|--------|------|------|----------------------|
| **Frontend** | React/TypeScript | Mature ecosystem, strong typing, excellent i18n | Bundle size, complexity | Vue.js, Svelte |
| **Backend** | Flask + Gunicorn | Lightweight, flexible, Python ecosystem | Not async-native | FastAPI, Django |
| **Queue** | Celery + Redis | Battle-tested, monitoring tools | Complex setup | RQ, Dramatiq |
| **ML** | faster-whisper | 4x faster than OpenAI Whisper | GPU setup complexity | OpenAI API, AssemblyAI |
| **Video** | FFmpeg | Industry standard, comprehensive | Learning curve | GStreamer |
| **Download** | yt-dlp | Active fork, YouTube-proof | Fragile to site changes | pytube, youtube-dl |

### Performance Characteristics

**CPU Intensive Operations**:
- Whisper transcription (benefits from GPU acceleration)
- FFmpeg video encoding/muxing
- yt-dlp video download parsing

**Memory Usage Patterns**:
- Whisper models: 1-3GB depending on size (config.py:33-34)
- Video files: Temporary 2x storage during processing
- Worker processes: 4-8GB reservation per concurrent task

**I/O Bottlenecks**:
- Network: YouTube download bandwidth
- Disk: Video file read/write operations
- Redis: Task state and result storage

## Non-Functional Requirements

### Performance & Scalability

**Current Limits**:
- **Concurrent Tasks**: 1 worker (configurable to N cores)
- **File Size**: 500MB limit (config.py:28)
- **Model Selection**: Auto-scaling from tinyâ†’large based on content
- **Processing Time**: 2-15 minutes for typical 10-minute video

**Scaling Strategy**:
```python
# Horizontal Scaling Pattern
worker_replicas = max(1, cpu_cores // 2)
memory_per_worker = "4-8GB"
queue_partitioning = ["processing", "cleanup", "priority"]
```

### Reliability & Fault Tolerance

**Error Recovery** (`core/exceptions.py`):
- **Structured Exception Hierarchy**: 15+ specific error types
- **Retry Logic**: Exponential backoff for network operations
- **Circuit Breaking**: Protection against external service failures
- **Graceful Degradation**: Fallback to smaller models on resource constraints

**Idempotency Design**:
- All tasks support safe retries via unique request IDs
- File operations use atomic moves and cleanup
- State updates are transactional through Redis

### Security Posture

**Current Protections**:
- âœ… Input validation (file types, sizes, URL patterns)
- âœ… Path traversal prevention (`secure_filename`)
- âœ… CORS configuration
- âœ… Dependency scanning in CI

**Security Roadmap**:
- ðŸ”„ Rate limiting implementation (Flask-Limiter)
- ðŸ”„ Authentication framework (JWT + user sessions)
- ðŸ”„ URL allowlisting for SSRF protection
- ðŸ”„ File content validation beyond extensions

### Observability Stack

**Current State**:
- **Logging**: Structured JSON logs via structlog (logging_config.py:40-80)
- **Health Checks**: Basic `/health` endpoint
- **Metrics**: Task completion/failure counts in Celery

**Production Requirements**:
```yaml
Metrics:     Prometheus + Grafana
Tracing:     Jaeger/Zipkin for request correlation  
Alerting:    PagerDuty/Slack integration
Dashboards:  Processing times, error rates, queue depth
```

### Internationalization Architecture

**Language Support Matrix**:
| Language | UI Translation | Transcription | Translation | RTL Support |
|----------|---------------|---------------|-------------|-------------|
| Hebrew   | âœ… Complete    | âœ… Native      | âœ… Target    | âœ… Full     |
| English  | âœ… Complete    | âœ… Native      | âœ… Source    | âŒ N/A      |
| Arabic   | âœ… Complete    | âœ… Native      | âœ… Both      | âœ… Full     |
| Spanish  | âœ… Complete    | âœ… Native      | âœ… Both      | âŒ N/A      |
| Other    | âŒ Fallback    | âœ… Extended    | âœ… ML-only   | âŒ Limited  |

**Technical Implementation**:
- **Frontend**: i18next with namespace organization (`public/locales/{lang}/{namespace}.json`)
- **Backend**: Python i18n with message catalogs (`backend/i18n/locales/`)
- **Shared Config**: Language metadata synchronization (`shared_config.py`)

## Deployment & Runtime Topology

### Docker Compose Services

| Service | Image | Port | Purpose | Resource Limits |
|---------|-------|------|---------|-----------------|
| `frontend` | nginx:alpine | 80 | Static React app serving | 512MB RAM |
| `backend` | python:3.9-slim | 8081 | Flask API server | 2GB RAM |
| `worker` | python:3.9-slim | - | Celery task processor | 8GB RAM |
| `beat` | python:3.9-slim | - | Scheduled task runner | 512MB RAM |
| `redis` | redis:alpine | 6379 | Message broker + cache | 1GB RAM |

### Network Architecture

```
Internet â†’ [Port 80] â†’ Frontend (Nginx) 
                        â†“ reverse proxy
                      Backend (Flask :8081)
                        â†“ task dispatch  
                      Redis (:6379) â† Worker Pool
                        â†“ results
                      File Storage (mounted volumes)
```

### Volume Strategy

```yaml
Persistent Volumes:
  ./backend/whisper_models:/app/whisper_models  # ML model cache
  ./backend/assets:/app/assets                  # Static resources

Ephemeral Volumes:  
  ./backend/uploads:/app/uploads                # Temp input files
  ./backend/downloads:/app/downloads            # Output artifacts
```

### Environment Configuration

**Development** (`docker-compose.yml`):
- Single worker instance
- Debug logging enabled
- Host volume mounts for hot reloading
- Memory limits for safety

**Production Considerations**:
```yaml
# Recommended Production Overrides
worker_replicas: 4-8                    # Based on CPU cores
memory_limits: 
  backend: 4GB
  worker: 8GB                          # For large Whisper models
  redis: 2GB                           # Queue + result storage
healthcheck_interval: 30s
restart_policy: unless-stopped
```

## API Overview

### Endpoint Categories

**Processing Endpoints**:
```http
POST /youtube              # Full YouTube processing pipeline
POST /upload               # Local file processing pipeline  
POST /download-video-only  # YouTube download without processing
POST /embed_subtitles      # Manual subtitle burn-in
```

**Status & Management**:
```http
GET  /status/{task_id}     # Real-time progress polling
GET  /download-with-token/{token}  # Secure file download
GET  /health               # Service health check
GET  /languages            # Supported language metadata
```

### Request/Response Patterns

**Standard Success Response**:
```json
{
  "task_id": "uuid-v4",
  "status": "PROGRESS|SUCCESS|FAILURE", 
  "result": {
    "files": {
      "original_srt": "filename.srt",
      "translated_srt": "filename_he.srt", 
      "video_with_subtitles": "filename_final.mp4"
    },
    "metadata": { "duration": 180, "title": "..." },
    "progress": { "overall_percent": 100, "current_step": "completed" }
  }
}
```

### Versioning Strategy

**Current State**: Unversioned API (technical debt)
**Migration Plan**: 
1. Introduce `/v1/` prefix for all endpoints
2. Maintain compatibility aliases during transition
3. Implement API deprecation headers and documentation

## Data Flow & Processing Pipeline

### YouTube Processing Sequence

```mermaid
sequenceDiagram
    participant U as User
    participant F as Frontend  
    participant B as Backend
    participant W as Worker
    participant Y as YouTube
    participant M as ML Services

    U->>F: Submit YouTube URL
    F->>B: POST /youtube {url, options}
    B->>W: Queue task (Celery)
    B->>F: Return task_id
    
    W->>Y: Download video (yt-dlp)
    W->>W: Extract audio (FFmpeg)
    W->>M: Transcribe (Whisper) 
    W->>M: Translate (Google/OpenAI)
    W->>W: Generate subtitles (SRT)
    W->>W: Mux video + subs (FFmpeg)
    W->>B: Update progress (Redis)
    
    F->>B: Poll /status/{task_id} 
    B->>F: Return progress updates
    F->>U: Display real-time progress
    
    W->>B: Complete task + generate download tokens
    F->>B: GET /download-with-token/{token}
    B->>F: Serve processed files
```

### State Machine Implementation

**Task States** (`state_manager.py:16-32`):
```python
class TaskState(Enum):
    PENDING  = "PENDING"    # Queued, not started
    PROGRESS = "PROGRESS"   # Currently processing  
    SUCCESS  = "SUCCESS"    # Completed successfully
    FAILURE  = "FAILURE"    # Terminal error state

class StepStatus(Enum):
    WAITING     = "waiting"      # Step not yet started
    IN_PROGRESS = "in_progress"  # Currently executing
    COMPLETED   = "completed"    # Successfully finished
    ERROR       = "error"        # Failed with retry possibility
```

**Progress Calculation**:
```python
# Step Weights (tasks.py:748-770)
steps_config = [
    {"label": "download_video", "weight": 0.20},
    {"label": "extract_audio", "weight": 0.15}, 
    {"label": "transcribe", "weight": 0.35},
    {"label": "translate", "weight": 0.15},
    {"label": "create_video", "weight": 0.15}
]

overall_progress = sum(step.progress * step.weight for step in steps)
```

### File Lifecycle Management

**Processing Flow**:
1. **Upload** â†’ Secure temp storage (`/app/uploads/{uuid}/`)
2. **Processing** â†’ Worker-specific workspace  
3. **Output** â†’ Downloads folder with cleanup timer
4. **Cleanup** â†’ Celery Beat task every 6 hours

**Security Measures**:
- Filename sanitization (`tasks.py:43-62`)
- Path traversal prevention
- File type validation beyond extensions
- Size limits with graceful handling

## Technology Choices & Trade-offs

### ML Pipeline Decisions

**Whisper Implementation** (`whisper_smart.py`):
```python
# Model Selection Logic
def select_optimal_model(duration, language, quality_preference):
    if duration < 300:      return "tiny"    # Fast for short content
    elif language == "en":  return "medium"  # Optimized for English
    elif quality == "high": return "large"   # Best accuracy
    else:                   return "base"    # Balanced default
```

**Trade-offs**:
- **faster-whisper vs OpenAI API**: 4x faster local processing vs API rate limits
- **Model caching**: Disk space vs download time on cold starts
- **CPU vs GPU**: Broader compatibility vs performance

### Translation Architecture

**Service Abstraction** (`translation_services.py:20-100`):
```python
class TranslationService:
    def translate(text, source_lang, target_lang): pass

class GoogleTranslateService(TranslationService): 
    # Free tier, good quality, rate limited
    
class OpenAITranslateService(TranslationService):
    # API costs, excellent quality, context aware
```

### Container Strategy

**Multi-stage Build Benefits**:
- Reduced image size (Python slim base)
- Security (non-root user execution)
- Reproducible builds with locked dependencies

**Volume Mount Strategy**:
- **Development**: Host mounts for hot reloading
- **Production**: Named volumes for persistence

## Non-Functional Requirements

### Performance Profile

**Benchmarks** (typical 10-minute video):
```
Download (YouTube):    2-5 minutes  (network dependent)
Audio Extraction:      30-60 seconds (FFmpeg) 
Transcription:         3-8 minutes   (model dependent)
Translation:           30-60 seconds (API dependent)
Video Muxing:          2-4 minutes   (FFmpeg)
Total Pipeline:        8-18 minutes
```

**Resource Utilization**:
- **CPU**: Transcription (80%), Video Processing (60%)
- **Memory**: Peak 6GB during large model loading
- **Disk**: 2-3x video file size during processing
- **Network**: YouTube download bandwidth + translation API calls

### Reliability Mechanisms

**Retry Strategies** (`tasks.py:580-650`):
```python
# Network Operations
@retry(stop=stop_after_attempt(3), wait=wait_exponential(min=1, max=10))
def download_with_retry():
    pass

# Processing Operations  
@retry(stop=stop_after_attempt(2), wait=wait_fixed(5))
def process_with_fallback():
    pass
```

**Graceful Degradation**:
- Model fallback: largeâ†’mediumâ†’baseâ†’tiny on memory constraints
- Quality reduction: Highâ†’mediumâ†’low on network issues
- Service fallback: OpenAIâ†’Google translation on quota limits

### Security Architecture

**Input Validation Framework**:
```python
# File Upload Security (app.py:400-500)
def validate_upload(file):
    check_file_extension(file.filename)     # Extension allowlist
    check_file_size(file, MAX_SIZE)         # Size limits
    check_mime_type(file)                   # Content validation
    sanitize_filename(file.filename)        # Path traversal prevention
```

**URL Validation** (Future Implementation):
```python
# SSRF Protection Strategy
ALLOWED_DOMAINS = {"youtube.com", "youtu.be", "m.youtube.com"}
def validate_url(url):
    parsed = urlparse(url)
    return parsed.hostname in ALLOWED_DOMAINS
```

## Risks & Future Work

### Current Limitations

**Immediate Risks** (Next 30 Days):
1. **No Rate Limiting**: DoS vulnerability on all endpoints
2. **Single Worker**: Processing bottleneck under load
3. **No Authentication**: Open access to compute resources
4. **Limited Monitoring**: Reactive incident response only

**Technical Debt** (Next 90 Days):
1. **API Versioning**: Breaking changes without migration path
2. **Database Layer**: File-based state limits scalability 
3. **Caching Strategy**: No CDN for static assets
4. **Error Aggregation**: Manual log analysis required

### Scaling Roadmap

**Phase 1: Production Hardening**
- Rate limiting + authentication
- Comprehensive monitoring stack
- Load testing suite
- Security audit + penetration testing

**Phase 2: Performance Optimization**
- Auto-scaling worker pools
- GPU acceleration for Whisper
- CDN integration for downloads
- Database migration for metadata

**Phase 3: Feature Enhancement** 
- Real-time processing (WebSocket updates)
- Batch processing APIs
- Advanced subtitle editing
- Multi-tenant architecture

## Directory Layout

```
SubsTranslator/
â”œâ”€â”€ ðŸ³ Infrastructure
â”‚   â”œâ”€â”€ docker-compose.yml       # Service orchestration
â”‚   â”œâ”€â”€ backend.Dockerfile       # Python app container
â”‚   â”œâ”€â”€ frontend.Dockerfile      # React app container  
â”‚   â””â”€â”€ nginx.conf               # Reverse proxy config
â”‚
â”œâ”€â”€ ðŸ”§ Backend (Python/Flask)
â”‚   â”œâ”€â”€ app.py                   # Flask application entry
â”‚   â”œâ”€â”€ config.py                # Environment configuration
â”‚   â”œâ”€â”€ tasks.py                 # Celery task definitions
â”‚   â”œâ”€â”€ celery_worker.py         # Worker process entry
â”‚   â”œâ”€â”€ core/exceptions.py       # Error handling framework
â”‚   â”œâ”€â”€ services/                # Business logic layer
â”‚   â”œâ”€â”€ i18n/                    # Backend internationalization
â”‚   â””â”€â”€ tests/                   # Unit + integration tests
â”‚
â”œâ”€â”€ ðŸŽ¨ Frontend (React/TypeScript)
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/          # React component library
â”‚   â”‚   â”œâ”€â”€ hooks/useApi.ts      # Backend communication
â”‚   â”‚   â”œâ”€â”€ contexts/            # Global state management
â”‚   â”‚   â”œâ”€â”€ i18n/                # Frontend internationalization
â”‚   â”‚   â””â”€â”€ types/               # TypeScript definitions
â”‚   â”œâ”€â”€ public/locales/          # Translation files
â”‚   â””â”€â”€ tests/                   # Component + E2E tests
â”‚
â”œâ”€â”€ ðŸ“š Documentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md          # This document
â”‚   â”œâ”€â”€ DEV_GUIDE.md            # Development workflow
â”‚   â””â”€â”€ PROJECT_OVERVIEW.md     # Business context
â”‚
â””â”€â”€ ðŸ› ï¸ Operations
    â”œâ”€â”€ scripts/start.sh         # Development startup
    â”œâ”€â”€ scripts/stop.sh          # Graceful shutdown
    â””â”€â”€ .github/workflows/       # CI/CD pipeline
```

## Glossary

**FFmpeg**: Swiss-army knife for video/audio processing. Used for audio extraction, subtitle burn-in, and video muxing.

**yt-dlp**: Python library for downloading videos from YouTube and 1000+ other sites. Active fork of youtube-dl with better reliability.

**Whisper**: OpenAI's speech-to-text model. "faster-whisper" is an optimized implementation providing 4x speed improvement.

**SRT**: SubRip Subtitle format. Plain text with timestamps: `[00:01:30 --> 00:01:35] Subtitle text here`

**Muxing**: Multiplexing - combining video, audio, and subtitle streams into a single container file.

**RTL**: Right-to-Left text direction for languages like Hebrew and Arabic, requiring special CSS and font handling.

**Celery**: Distributed task queue for Python. Handles asynchronous processing with Redis as message broker.

**State Machine**: Finite State Machine (FSM) pattern for tracking multi-step processing with progress updates and error recovery.

---

*Last Updated: 2025-08-31*  
*Document Version: 1.0*  
*Target Audience: Senior Engineers + SRE Teams*